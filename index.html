<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jeonghwan Lee</title>

    <<met  nam=="author  conten=="Jeonghwan Lee>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jeonghwan Lee
                </p>
                <p>
		I'm an undergraduate student majoring in Artificial Intelligence at <a href="https://www.catholic.ac.kr/ko/index.do">CUK</a>. 
		I'm currently working as an undergraduate researcher at <a href="https://midi-troodon-3dc.notion.site/Welcome-to-CUK-NLP-Lab-b1f7c3724e4045568ff76eba6e94b50d"> CUK NLP LAB</a>, advised by Prof. <a href="https://scholar.google.com/citations?user=PQsJWfsAAAAJ&hl=ko">Kangmin Kim</a>.
		My current interests include in World models, Action planning, Robotics.
                </p>
                <p style="text-align:center">
                  <a href="mailto:go2gym365@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/JeonghwanLee-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://github.com/go2gym365">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="radmesh_stop()" onmouseover="radmesh_start()" bgcolor="#ffffd0">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/radmesh_after.jpg' width=100%>
      </div>
      <img src='images/radmesh_before.jpg' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://half-potato.gitlab.io/rm/">
      <span class="papertitle">Radiance Meshes for Volumetric Reconstruction</span>
    </a>
    <br>
    <a href="https://half-potato.gitlab.io/">Alexander Mai</a>,
    <a href="https://github.com/Shmaug">Trevor Hedstrom</a>,
    <a href="https://grgkopanas.github.io/">George Kopanas</a>, <br>
	<a href="https://mediatech.aalto.fi/~janne/index.php">Janne Kontkanen</a>, 
    <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
    <strong>Jonathan T. Barron</strong>
    <br>
    <em>arXiv</em>, 2025
    <br>
    <a href="https://half-potato.gitlab.io/rm/">project page</a>
    /
    <a href="https://arxiv.org/abs/2512.04076">arXiv</a>
    <p></p>
    <p>
	Parameterizing a scene with a Delaunay tetrahedralization and a neural field yields a scene representation that is accurate, fast to render, easy to edit, and backwards-compatible.
    </p>
  </td>
</tr>

<tr onmouseout="nexf_stop()" onmouseover="nexf_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nexf_image'>
					  <img src='images/nexf_after.jpg' width=100%>
					</div>
          <img src='images/nexf_before.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nexf_start() {
            document.getElementById('nexf_image').style.opacity = "1";
          }

          function nexf_stop() {
            document.getElementById('nexf_image').style.opacity = "0";
          }
          nexf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://m-niemeyer.github.io/nexf/">
          <span class="papertitle">NExF: Learning Neural Exposure Fields for View Synthesis</span>
        </a>
        <br>
        <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>,
        <a href="https://campar.in.tum.de/Main/FabianManhardt">Fabian Manhardt</a>,
        <a href="http://www.lix.polytechnique.fr/Labo/Marie-Julie.RAKOTOSAONA/">Marie-Julie Rakotosaona</a>,
        <a href="https://moechsle.github.io">Michael Oechsle</a>,
        <a href="https://ait.ethz.ch/people/ctsalico">Christina Tsalicoglou</a>,
        <a href="https://scholar.google.com/citations?user=ml3laqEAAAAJ&hl=ja">Keisuke Tateno</a>,
        <strong>Jonathan T. Barron</strong>,
        <a href="https://federicotombari.github.io/">Federico Tombari</a>
        <br>
        <em>NeurIPS</em>, 2025
        <br>
        <a href="https://m-niemeyer.github.io/nexf/">project page</a>
        /
        <a href="https://arxiv.org/abs/2510.08279">arXiv</a>
        <p></p>
        <p>
		Learning a neural field that optimizes exposure for each 3D point enables high-quality 3D-consistent view synthesis despite extreme exposure variation during capture.
        </p>
      </td>
    </tr>
